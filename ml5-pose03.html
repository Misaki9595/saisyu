<!DOCTYPE html>

<html>
  <head>
    <meta charset="UTF-8" />
    <title>ビデオで認識</title>
    <!-- 1. ここにP5.jsを読み込む -->
    <script src="https://cdn.jsdelivr.net/npm/p5"></script>
    <script src="https://unpkg.com/ml5@0.4.3/dist/ml5.min.js"></script>

    <!-- 2.以下にsetup関数とdraw関数を定義 -->

    <script>
      let video;
      let poseNet;
      let poses = [];
      let skeletons = [];
      let kao = [];
      let tori;
      let text1;

      // function onsei(){

      function preload() {
        kao[0] = loadImage("kao.png");
        kao[1] = loadImage("hen.png");
      }

      function setup() {
        createCanvas(640, 480);
        video = createCapture(VIDEO);

        // Create a new poseNet method with a single detection
        poseNet = ml5.poseNet(video, modelReady);
        // This sets up an event that fills the global variable "poses"
        // with an array every time new poses are detected
        poseNet.on("pose", function (results) {
          poses = results;
        });
        // Hide the video element, and just show the canvas
        video.hide();
      }

      function modelReady() {
        select("#status").html("Model Loaded");
      }

      function draw() {
        image(video, 0, 0, width, height);

        // We can call both functions to draw all keypoints and the skeletons
        drawKeypoints();
        drawSkeleton();
        // textmoji();
      }

      // A function to draw ellipses over the detected keypoints
      function drawKeypoints() {
        for (let i = 0; i < poses.length; i += 1) {
            const keypoints = predictions[i].scaledMesh;

            let x1 = poses[i].pose.keypoints[1].x;
            let y1 = poses[i].pose.keypoints[1].y;
            let x2 = poses[i].pose.keypoints[2].x;
            let y2 = poses[i].pose.keypoints[2].y;

            // const[x1, y1] = keypoints[1];
            // const[x2, y2] = keypoints[2];
            let distance = Math.sqrt(
               (x1 - x2) * (x1 - x2) + (y1 - y2) * (y1 - y2)
          );
        }
        // Loop through all the poses detected
        for (let i = 0; i < poses.length; i++) {
          // For each pose detected, loop through all the keypoints
          for (let j = 0; j < poses[i].pose.keypoints.length; j++) {
            // A keypoint is an object describing a body part (like rightArm or leftShoulder)
            let keypoint = poses[i].pose.keypoints[0];
            // Only draw an ellipse is the pose probability is bigger than 0.2
            if (keypoint.score > 0.2) {
              if (keypoint.position.x < width / 2) {
                image(kao[1], keypoint.position.x -300, keypoint.position.y -220, 0, 0);
                speak(text);
              } else {
                image(kao[0], keypoint.position.x -100, keypoint.position.y -100, 0, 0);
                speak(text2);
              }
              // fill(10, 10, 10);
            }
          }
          // const[x, y] = keypoint[0];
          // fill(255, 0, 0);
          // ellipse(keypoint.position.x, keypoint.position.y, 10, 10);
          for (let j = 0; j < poses[i].pose.keypoints.length; j++) {
            // A keypoint is an object describing a body part (like rightArm or leftShoulder)
            let keypoint = poses[i].pose.keypoints[2];
            // Only draw an ellipse is the pose probability is bigger than 0.2
            if (keypoint.score > 0.2) {
              fill(255, 255, 0);
              noStroke();
              // ellipse(keypoint.position.x, keypoint.position.y, 10, 10);
              // text(text, keypoint.position.x, keypoint.position.y);
              // fill(10, 10, 10);
            }
          }
        }
      }
      let msg = new SpeechSynthesisUtterance();
      let voices = window.speechSynthesis.getVoices();

      let text = "ミラクルチェンジ";
      function speak(text) {
        // 以下オプション設定
        msg.voice = voices[7]; // 7:Google 日本人 ja-JP ※他は英語のみ
        msg.volume = 1.0; // 音量 min 0 ~ max 1
        msg.rate = 1; // 速度 min 0 ~ max 10
        msg.pitch = 1.0; // 音程 min 0 ~ max 2

        msg.text = text; // 喋る内容
        msg.lang = "ja-JP"; // en-US or ja-JP
        // msg.lang = 'en-US'; // en-US or ja-JP

        // 発話実行
        speechSynthesis.speak(msg);
      }

      msg.onend = function (event) {
        console.log("End: ", text);
      };

      let text2 = "変身しよう!";
      function speak(text2) {
        // 以下オプション設定
        msg.voice = voices[7]; // 7:Google 日本人 ja-JP ※他は英語のみ
        msg.volume = 1.0; // 音量 min 0 ~ max 1
        msg.rate = 1; // 速度 min 0 ~ max 10
        msg.pitch = 2.0; // 音程 min 0 ~ max 2

        msg.text = text2; // 喋る内容
        msg.lang = "ja-JP"; // en-US or ja-JP
        // msg.lang = 'en-US'; // en-US or ja-JP

        // 発話実行
        speechSynthesis.speak(msg);
      }

      // 終了時の処理
      msg.onend = function (event) {
        console.log("End: ", text2);
      };

      // A function to draw the skeletons
      function drawSkeleton() {
        // Loop through all the skeletons detected
        for (let i = 0; i < poses.length; i++) {
          // For every skeleton, loop through all body connections
          for (let j = 0; j < poses[i].skeleton.length; j++) {
            let partA = poses[i].skeleton[j][0];
            let partB = poses[i].skeleton[j][1];
            stroke(255, 0, 0);
            line(
              partA.position.x,
              partA.position.y,
              partB.position.x,
              partB.position.y
            );
          }
        }
      }

      // function getpic() {
      //   //const pic = document.querySelector("#pic");
      //   image(kao);
      //   // pic.src ="image/kana.png";
      //   kao.setAttribute(nyan);
      // }
    </script>
  </head>
  <body>
    <div id="status"></div>
    <div id="result"></div>
    <div id="probability"></div>
  </body>
</html>
